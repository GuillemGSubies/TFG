{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTO 1\n",
    "\n",
    "* Métrica Perplejidad: https://en.wikipedia.org/wiki/Perplexity#cite_ref-1\n",
    "\n",
    "* Loss: Categorical Crossentropy (buscar más referencias para ambos)\n",
    "\n",
    "* Arquitectura: Capa average, capa max y capa densa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@InProceedings{Danescu-Niculescu-Mizil+Lee:11a,\n",
    "\n",
    "  author={Cristian Danescu-Niculescu-Mizil and Lillian Lee},\n",
    "\n",
    "  title={Chameleons in imagined conversations:\n",
    "\n",
    "  A new approach to understanding coordination of linguistic style in dialogs.},\n",
    "\n",
    "  booktitle={Proceedings of the\n",
    "\n",
    "        Workshop on Cognitive Modeling and Computational Linguistics, ACL 2011},\n",
    "\n",
    "  year={2011}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = \"\"\"Con diez cañones por banda,\n",
    "viento en popa a toda vela,\n",
    "no corta el mar, sino vuela,\n",
    "un velero bergantín;\n",
    "bajel pirata que llaman\n",
    "por su bravura el Temido\n",
    "en todo el mar conocido\n",
    "del uno al otro confín.\n",
    "La luna en el mar riela,\n",
    "en la lona gime el viento\n",
    "y alza en blando movimiento\n",
    "olas de plata y azul;\n",
    "y ve el capitán pirata,\n",
    "cantando alegre en la popa,\n",
    "Asia a un lado, al otro Europa,\n",
    "Y allá a su frente Estambul:\n",
    "-Navega, velero mío,\n",
    "sin temor\n",
    "que ni enemigo navío,\n",
    "ni tormenta, ni bonanza\n",
    "tu rumbo a torcer alcanza,\n",
    "ni a sujetar tu valor.\n",
    "Veinte presas\n",
    "hemos hecho\n",
    "a despecho\n",
    "del inglés\n",
    "y han rendido\n",
    "sus pendones\n",
    "cien naciones\n",
    "a mis pies.\n",
    "Que es mi barco mi tesoro,\n",
    "que es mi Dios la libertad;\n",
    "mi ley, la fuerza y el viento;\n",
    "mi única patria, la mar.\n",
    "Allá muevan feroz guerra\n",
    "ciegos reyes\n",
    "por un palmo más de tierra,\n",
    "que yo tengo aquí por mío\n",
    "cuanto abarca el mar bravío\n",
    "a quien nadie impuso leyes.\n",
    "Y no hay playa\n",
    "sea cualquiera,\n",
    "ni bandera\n",
    "de esplendor,\n",
    "que no sienta\n",
    "mi derecho\n",
    "y dé pecho\n",
    "a mi valor\n",
    "Que es mi barco mi tesoro,\n",
    "que es mi Dios la libertad;\n",
    "mi ley, la fuerza y el viento;\n",
    "mi única patria, la mar.\n",
    "A la voz de ¡barco viene!,\n",
    "es de ver\n",
    "cómo vira y se previene\n",
    "a todo trapo a escapar:\n",
    "que yo soy el rey del mar\n",
    "y mi furia es de temer.\n",
    "En las presas\n",
    "yo divido\n",
    "lo cogido\n",
    "por igual:\n",
    "sólo quiero\n",
    "por riqueza\n",
    "la belleza\n",
    "sin rival.\n",
    "Que es mi barco mi tesoro,\n",
    "que es mi Dios la libertad;\n",
    "mi ley, la fuerza y el viento;\n",
    "mi única patria, la mar.\n",
    "¡Sentenciado estoy a muerte!\n",
    "Yo me río:\n",
    "no me abandone la suerte,\n",
    "y al mismo que me condena\n",
    "colgaré de alguna antena\n",
    "quizá en su propio navío.\n",
    "Y si caigo,\n",
    "¿qué es la vida?\n",
    "Por perdida\n",
    "ya la di\n",
    "cuando el yugo\n",
    "del esclavo\n",
    "como un bravo sacudí.\n",
    "Que es mi barco mi tesoro,\n",
    "que es mi Dios la libertad;\n",
    "mi ley, la fuerza y el viento;\n",
    "mi única patria, la mar.\n",
    "Son mi música mejor\n",
    "aquilones,\n",
    "el estrépito y temblor\n",
    "de los cables sacudidos\n",
    "del negro mar los bramidos\n",
    "y el rugir de mis cañones.\n",
    "Y del trueno\n",
    "al son violento,\n",
    "y del viento,\n",
    "al rebramar,\n",
    "yo me duermo\n",
    "sosegado,\n",
    "arrullado\n",
    "por el mar.\n",
    "Que es mi barco mi tesoro,\n",
    "que es mi Dios la libertad;\n",
    "mi ley, la fuerza y el viento;\n",
    "mi única patria, la mar.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to update CUDA in order to use GPU, so I disable this\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from src.model import Baseline, LSTM_Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_shapes():\n",
    "    print(f\"Shape of X_train: {X_train.shape}\")\n",
    "    print(f\"Shape of X_test: {X_test.shape}\")\n",
    "    print(f\"Shape of y_train: {y_train.shape}\")\n",
    "    print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (247, 6)\n",
      "Shape of X_test: (82, 6)\n",
      "Shape of y_train: (247, 194)\n",
      "Shape of y_test: (82, 194)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 6, 64)             12416     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 194)               74690     \n",
      "=================================================================\n",
      "Total params: 87,106\n",
      "Trainable params: 87,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 247 samples, validate on 82 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 5.2550 - perplexity_raw: 1.0000 - val_loss: 5.2450 - val_perplexity_raw: 1.0000\n",
      "Epoch 2/200\n",
      " - 0s - loss: 5.1867 - perplexity_raw: 1.0278 - val_loss: 5.2253 - val_perplexity_raw: 1.0629\n",
      "Epoch 3/200\n",
      " - 0s - loss: 5.1152 - perplexity_raw: 1.0487 - val_loss: 5.2045 - val_perplexity_raw: 1.0629\n",
      "Epoch 4/200\n",
      " - 0s - loss: 5.0280 - perplexity_raw: 1.0487 - val_loss: 5.1826 - val_perplexity_raw: 1.0629\n",
      "Epoch 5/200\n",
      " - 0s - loss: 4.9187 - perplexity_raw: 1.0487 - val_loss: 5.1628 - val_perplexity_raw: 1.0629\n",
      "Epoch 6/200\n",
      " - 0s - loss: 4.7924 - perplexity_raw: 1.0487 - val_loss: 5.1454 - val_perplexity_raw: 1.0629\n",
      "Epoch 7/200\n",
      " - 0s - loss: 4.6473 - perplexity_raw: 1.0626 - val_loss: 5.1352 - val_perplexity_raw: 1.0838\n",
      "Epoch 8/200\n",
      " - 0s - loss: 4.4919 - perplexity_raw: 1.0765 - val_loss: 5.1388 - val_perplexity_raw: 1.0838\n",
      "Epoch 9/200\n",
      " - 0s - loss: 4.3389 - perplexity_raw: 1.0835 - val_loss: 5.1556 - val_perplexity_raw: 1.1048\n",
      "Epoch 10/200\n",
      " - 0s - loss: 4.1856 - perplexity_raw: 1.0974 - val_loss: 5.1866 - val_perplexity_raw: 1.1048\n",
      "Epoch 11/200\n",
      " - 0s - loss: 4.0559 - perplexity_raw: 1.1043 - val_loss: 5.2245 - val_perplexity_raw: 1.1048\n",
      "Epoch 12/200\n",
      " - 0s - loss: 3.9220 - perplexity_raw: 1.1252 - val_loss: 5.2573 - val_perplexity_raw: 1.1257\n",
      "Epoch 13/200\n",
      " - 0s - loss: 3.8026 - perplexity_raw: 1.1461 - val_loss: 5.2809 - val_perplexity_raw: 1.1257\n",
      "Epoch 14/200\n",
      " - 0s - loss: 3.6743 - perplexity_raw: 1.1600 - val_loss: 5.2943 - val_perplexity_raw: 1.1257\n",
      "Epoch 15/200\n",
      " - 0s - loss: 3.5530 - perplexity_raw: 1.1530 - val_loss: 5.2953 - val_perplexity_raw: 1.1257\n",
      "Epoch 16/200\n",
      " - 0s - loss: 3.4216 - perplexity_raw: 1.1322 - val_loss: 5.2956 - val_perplexity_raw: 1.1257\n",
      "Epoch 17/200\n",
      " - 0s - loss: 3.2911 - perplexity_raw: 1.1530 - val_loss: 5.2871 - val_perplexity_raw: 1.1467\n",
      "Epoch 18/200\n",
      " - 0s - loss: 3.1610 - perplexity_raw: 1.1461 - val_loss: 5.2847 - val_perplexity_raw: 1.1257\n",
      "Epoch 19/200\n",
      " - 0s - loss: 3.0321 - perplexity_raw: 1.1600 - val_loss: 5.2853 - val_perplexity_raw: 1.1048\n",
      "Epoch 20/200\n",
      " - 0s - loss: 2.9121 - perplexity_raw: 1.1530 - val_loss: 5.2899 - val_perplexity_raw: 1.1048\n",
      "Epoch 21/200\n",
      " - 0s - loss: 2.7875 - perplexity_raw: 1.1391 - val_loss: 5.3004 - val_perplexity_raw: 1.1048\n",
      "Epoch 22/200\n",
      " - 0s - loss: 2.6694 - perplexity_raw: 1.1461 - val_loss: 5.3126 - val_perplexity_raw: 1.1257\n",
      "Epoch 23/200\n",
      " - 0s - loss: 2.5522 - perplexity_raw: 1.1530 - val_loss: 5.3299 - val_perplexity_raw: 1.1257\n",
      "Epoch 24/200\n",
      " - 0s - loss: 2.4371 - perplexity_raw: 1.1530 - val_loss: 5.3456 - val_perplexity_raw: 1.1257\n",
      "Epoch 25/200\n",
      " - 0s - loss: 2.3270 - perplexity_raw: 1.1461 - val_loss: 5.3759 - val_perplexity_raw: 1.1048\n",
      "Epoch 26/200\n",
      " - 0s - loss: 2.2165 - perplexity_raw: 1.1391 - val_loss: 5.4049 - val_perplexity_raw: 1.1048\n",
      "Epoch 27/200\n",
      " - 0s - loss: 2.1109 - perplexity_raw: 1.1391 - val_loss: 5.4426 - val_perplexity_raw: 1.1048\n",
      "Epoch 28/200\n",
      " - 0s - loss: 2.0048 - perplexity_raw: 1.1252 - val_loss: 5.4793 - val_perplexity_raw: 1.1048\n",
      "Epoch 29/200\n",
      " - 0s - loss: 1.9037 - perplexity_raw: 1.1183 - val_loss: 5.5241 - val_perplexity_raw: 1.1048\n",
      "Epoch 30/200\n",
      " - 0s - loss: 1.8075 - perplexity_raw: 1.1183 - val_loss: 5.5705 - val_perplexity_raw: 1.1048\n",
      "Epoch 31/200\n",
      " - 0s - loss: 1.7186 - perplexity_raw: 1.1183 - val_loss: 5.6147 - val_perplexity_raw: 1.1048\n",
      "Epoch 32/200\n",
      " - 0s - loss: 1.6299 - perplexity_raw: 1.1183 - val_loss: 5.6594 - val_perplexity_raw: 1.1048\n",
      "Epoch 33/200\n",
      " - 0s - loss: 1.5485 - perplexity_raw: 1.0974 - val_loss: 5.7115 - val_perplexity_raw: 1.1048\n",
      "Epoch 34/200\n",
      " - 0s - loss: 1.4712 - perplexity_raw: 1.0974 - val_loss: 5.7581 - val_perplexity_raw: 1.1048\n",
      "Epoch 35/200\n",
      " - 0s - loss: 1.3990 - perplexity_raw: 1.0974 - val_loss: 5.8098 - val_perplexity_raw: 1.1048\n",
      "Epoch 36/200\n",
      " - 0s - loss: 1.3342 - perplexity_raw: 1.0974 - val_loss: 5.8582 - val_perplexity_raw: 1.1048\n",
      "Epoch 37/200\n",
      " - 0s - loss: 1.2699 - perplexity_raw: 1.0904 - val_loss: 5.9114 - val_perplexity_raw: 1.1048\n",
      "Epoch 38/200\n",
      " - 0s - loss: 1.2102 - perplexity_raw: 1.0904 - val_loss: 5.9586 - val_perplexity_raw: 1.1048\n",
      "Epoch 39/200\n",
      " - 0s - loss: 1.1558 - perplexity_raw: 1.0904 - val_loss: 6.0025 - val_perplexity_raw: 1.1048\n",
      "Epoch 40/200\n",
      " - 0s - loss: 1.1041 - perplexity_raw: 1.0904 - val_loss: 6.0503 - val_perplexity_raw: 1.1048\n",
      "Epoch 41/200\n",
      " - 0s - loss: 1.0557 - perplexity_raw: 1.0904 - val_loss: 6.0979 - val_perplexity_raw: 1.1048\n",
      "Epoch 42/200\n",
      " - 0s - loss: 1.0107 - perplexity_raw: 1.0904 - val_loss: 6.1465 - val_perplexity_raw: 1.1048\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.9682 - perplexity_raw: 1.0904 - val_loss: 6.1922 - val_perplexity_raw: 1.1048\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.9283 - perplexity_raw: 1.0904 - val_loss: 6.2377 - val_perplexity_raw: 1.1048\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.8907 - perplexity_raw: 1.0904 - val_loss: 6.2853 - val_perplexity_raw: 1.1048\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.8570 - perplexity_raw: 1.0904 - val_loss: 6.3277 - val_perplexity_raw: 1.1048\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.8240 - perplexity_raw: 1.0904 - val_loss: 6.3676 - val_perplexity_raw: 1.1048\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.7940 - perplexity_raw: 1.0904 - val_loss: 6.4061 - val_perplexity_raw: 1.1048\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.7654 - perplexity_raw: 1.0904 - val_loss: 6.4454 - val_perplexity_raw: 1.1048\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.7383 - perplexity_raw: 1.0904 - val_loss: 6.4797 - val_perplexity_raw: 1.1048\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.7145 - perplexity_raw: 1.0904 - val_loss: 6.5151 - val_perplexity_raw: 1.1048\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.6896 - perplexity_raw: 1.0904 - val_loss: 6.5544 - val_perplexity_raw: 1.1048\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.6676 - perplexity_raw: 1.0904 - val_loss: 6.5921 - val_perplexity_raw: 1.1048\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.6453 - perplexity_raw: 1.0904 - val_loss: 6.6256 - val_perplexity_raw: 1.1048\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.6263 - perplexity_raw: 1.0904 - val_loss: 6.6597 - val_perplexity_raw: 1.1048\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.6077 - perplexity_raw: 1.0904 - val_loss: 6.6877 - val_perplexity_raw: 1.1048\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.5891 - perplexity_raw: 1.0904 - val_loss: 6.7249 - val_perplexity_raw: 1.1048\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.5738 - perplexity_raw: 1.0904 - val_loss: 6.7562 - val_perplexity_raw: 1.1048\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.5591 - perplexity_raw: 1.0904 - val_loss: 6.7915 - val_perplexity_raw: 1.1048\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.5445 - perplexity_raw: 1.0904 - val_loss: 6.8219 - val_perplexity_raw: 1.1048\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.5308 - perplexity_raw: 1.0904 - val_loss: 6.8445 - val_perplexity_raw: 1.1048\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.5191 - perplexity_raw: 1.0904 - val_loss: 6.8782 - val_perplexity_raw: 1.1048\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.5049 - perplexity_raw: 1.0904 - val_loss: 6.9049 - val_perplexity_raw: 1.1048\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.4963 - perplexity_raw: 1.0904 - val_loss: 6.9267 - val_perplexity_raw: 1.1048\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.4848 - perplexity_raw: 1.0904 - val_loss: 6.9531 - val_perplexity_raw: 1.1048\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.4746 - perplexity_raw: 1.0904 - val_loss: 6.9771 - val_perplexity_raw: 1.1048\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.4635 - perplexity_raw: 1.0904 - val_loss: 7.0031 - val_perplexity_raw: 1.1048\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.4573 - perplexity_raw: 1.0904 - val_loss: 7.0253 - val_perplexity_raw: 1.1048\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.4490 - perplexity_raw: 1.0904 - val_loss: 7.0514 - val_perplexity_raw: 1.1048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200\n",
      " - 0s - loss: 0.4411 - perplexity_raw: 1.0904 - val_loss: 7.0664 - val_perplexity_raw: 1.1048\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.4335 - perplexity_raw: 1.0835 - val_loss: 7.0887 - val_perplexity_raw: 1.1048\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.4273 - perplexity_raw: 1.0835 - val_loss: 7.1098 - val_perplexity_raw: 1.1048\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.4203 - perplexity_raw: 1.0835 - val_loss: 7.1301 - val_perplexity_raw: 1.1048\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.4151 - perplexity_raw: 1.0835 - val_loss: 7.1519 - val_perplexity_raw: 1.1048\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.4100 - perplexity_raw: 1.0835 - val_loss: 7.1735 - val_perplexity_raw: 1.1048\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.4037 - perplexity_raw: 1.0835 - val_loss: 7.1923 - val_perplexity_raw: 1.1048\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.3997 - perplexity_raw: 1.0904 - val_loss: 7.2141 - val_perplexity_raw: 1.1257\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.3945 - perplexity_raw: 1.1183 - val_loss: 7.2297 - val_perplexity_raw: 1.1257\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.3910 - perplexity_raw: 1.1183 - val_loss: 7.2513 - val_perplexity_raw: 1.1257\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.3852 - perplexity_raw: 1.1183 - val_loss: 7.2689 - val_perplexity_raw: 1.1257\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.3806 - perplexity_raw: 1.1183 - val_loss: 7.2840 - val_perplexity_raw: 1.1257\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.3777 - perplexity_raw: 1.0974 - val_loss: 7.2992 - val_perplexity_raw: 1.1048\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.3735 - perplexity_raw: 1.0974 - val_loss: 7.3185 - val_perplexity_raw: 1.1257\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.3707 - perplexity_raw: 1.0904 - val_loss: 7.3332 - val_perplexity_raw: 1.1048\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.3685 - perplexity_raw: 1.0835 - val_loss: 7.3490 - val_perplexity_raw: 1.1048\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.3655 - perplexity_raw: 1.0835 - val_loss: 7.3628 - val_perplexity_raw: 1.1048\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.3618 - perplexity_raw: 1.0835 - val_loss: 7.3788 - val_perplexity_raw: 1.1048\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.3601 - perplexity_raw: 1.0835 - val_loss: 7.3919 - val_perplexity_raw: 1.1048\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.3546 - perplexity_raw: 1.1043 - val_loss: 7.4108 - val_perplexity_raw: 1.1257\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.3545 - perplexity_raw: 1.1183 - val_loss: 7.4249 - val_perplexity_raw: 1.1257\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.3538 - perplexity_raw: 1.0835 - val_loss: 7.4314 - val_perplexity_raw: 1.1048\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.3488 - perplexity_raw: 1.0835 - val_loss: 7.4459 - val_perplexity_raw: 1.1048\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.3462 - perplexity_raw: 1.0835 - val_loss: 7.4602 - val_perplexity_raw: 1.1048\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.3451 - perplexity_raw: 1.0835 - val_loss: 7.4777 - val_perplexity_raw: 1.1048\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.3435 - perplexity_raw: 1.0835 - val_loss: 7.4884 - val_perplexity_raw: 1.1048\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.3405 - perplexity_raw: 1.0835 - val_loss: 7.4981 - val_perplexity_raw: 1.1048\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.3417 - perplexity_raw: 1.0835 - val_loss: 7.5079 - val_perplexity_raw: 1.1048\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.3382 - perplexity_raw: 1.0974 - val_loss: 7.5190 - val_perplexity_raw: 1.1257\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.3362 - perplexity_raw: 1.1183 - val_loss: 7.5292 - val_perplexity_raw: 1.1257\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.3345 - perplexity_raw: 1.0974 - val_loss: 7.5396 - val_perplexity_raw: 1.1048\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.3329 - perplexity_raw: 1.0835 - val_loss: 7.5505 - val_perplexity_raw: 1.1048\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.3323 - perplexity_raw: 1.0835 - val_loss: 7.5641 - val_perplexity_raw: 1.1257\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.3336 - perplexity_raw: 1.1183 - val_loss: 7.5719 - val_perplexity_raw: 1.1257\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.3297 - perplexity_raw: 1.1043 - val_loss: 7.5837 - val_perplexity_raw: 1.1048\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.3274 - perplexity_raw: 1.1113 - val_loss: 7.5938 - val_perplexity_raw: 1.1257\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.3272 - perplexity_raw: 1.0974 - val_loss: 7.6026 - val_perplexity_raw: 1.1048\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.3259 - perplexity_raw: 1.0835 - val_loss: 7.6127 - val_perplexity_raw: 1.1048\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.3241 - perplexity_raw: 1.0835 - val_loss: 7.6199 - val_perplexity_raw: 1.1048\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.3244 - perplexity_raw: 1.0904 - val_loss: 7.6298 - val_perplexity_raw: 1.1257\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.3238 - perplexity_raw: 1.0974 - val_loss: 7.6353 - val_perplexity_raw: 1.1048\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.3210 - perplexity_raw: 1.0835 - val_loss: 7.6465 - val_perplexity_raw: 1.1048\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.3215 - perplexity_raw: 1.0835 - val_loss: 7.6613 - val_perplexity_raw: 1.1048\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.3201 - perplexity_raw: 1.0835 - val_loss: 7.6684 - val_perplexity_raw: 1.1048\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.3179 - perplexity_raw: 1.0974 - val_loss: 7.6739 - val_perplexity_raw: 1.1257\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.3173 - perplexity_raw: 1.1183 - val_loss: 7.6838 - val_perplexity_raw: 1.1048\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.3157 - perplexity_raw: 1.0835 - val_loss: 7.6894 - val_perplexity_raw: 1.1048\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.3159 - perplexity_raw: 1.0835 - val_loss: 7.6944 - val_perplexity_raw: 1.1048\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.3154 - perplexity_raw: 1.0835 - val_loss: 7.7040 - val_perplexity_raw: 1.1048\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.3150 - perplexity_raw: 1.0835 - val_loss: 7.7146 - val_perplexity_raw: 1.1048\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.3137 - perplexity_raw: 1.0974 - val_loss: 7.7188 - val_perplexity_raw: 1.1257\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.3127 - perplexity_raw: 1.1183 - val_loss: 7.7296 - val_perplexity_raw: 1.1048\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.3125 - perplexity_raw: 1.0835 - val_loss: 7.7340 - val_perplexity_raw: 1.1048\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.3124 - perplexity_raw: 1.0835 - val_loss: 7.7380 - val_perplexity_raw: 1.1048\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.3105 - perplexity_raw: 1.0835 - val_loss: 7.7449 - val_perplexity_raw: 1.1048\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.3113 - perplexity_raw: 1.0835 - val_loss: 7.7515 - val_perplexity_raw: 1.1048\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.3088 - perplexity_raw: 1.0835 - val_loss: 7.7586 - val_perplexity_raw: 1.1048\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.3079 - perplexity_raw: 1.0835 - val_loss: 7.7671 - val_perplexity_raw: 1.1048\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.3098 - perplexity_raw: 1.0835 - val_loss: 7.7739 - val_perplexity_raw: 1.1048\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.3085 - perplexity_raw: 1.1043 - val_loss: 7.7799 - val_perplexity_raw: 1.1257\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.3086 - perplexity_raw: 1.1183 - val_loss: 7.7916 - val_perplexity_raw: 1.1257\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.3098 - perplexity_raw: 1.1113 - val_loss: 7.7931 - val_perplexity_raw: 1.1048\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.3059 - perplexity_raw: 1.0835 - val_loss: 7.7995 - val_perplexity_raw: 1.1048\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.3070 - perplexity_raw: 1.0835 - val_loss: 7.8068 - val_perplexity_raw: 1.1048\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.3063 - perplexity_raw: 1.1113 - val_loss: 7.8117 - val_perplexity_raw: 1.1048\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.3060 - perplexity_raw: 1.0835 - val_loss: 7.8177 - val_perplexity_raw: 1.1048\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.3046 - perplexity_raw: 1.0835 - val_loss: 7.8209 - val_perplexity_raw: 1.1048\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.3043 - perplexity_raw: 1.0835 - val_loss: 7.8310 - val_perplexity_raw: 1.1048\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.3054 - perplexity_raw: 1.0835 - val_loss: 7.8395 - val_perplexity_raw: 1.1048\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.3045 - perplexity_raw: 1.0835 - val_loss: 7.8443 - val_perplexity_raw: 1.1048\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.3043 - perplexity_raw: 1.0835 - val_loss: 7.8469 - val_perplexity_raw: 1.1048\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.3019 - perplexity_raw: 1.0835 - val_loss: 7.8539 - val_perplexity_raw: 1.1048\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.3020 - perplexity_raw: 1.1183 - val_loss: 7.8634 - val_perplexity_raw: 1.1257\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.3012 - perplexity_raw: 1.1113 - val_loss: 7.8677 - val_perplexity_raw: 1.1257\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.3008 - perplexity_raw: 1.1183 - val_loss: 7.8693 - val_perplexity_raw: 1.1257\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.3004 - perplexity_raw: 1.1183 - val_loss: 7.8780 - val_perplexity_raw: 1.1048\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.3007 - perplexity_raw: 1.0835 - val_loss: 7.8815 - val_perplexity_raw: 1.1048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200\n",
      " - 0s - loss: 0.2995 - perplexity_raw: 1.0835 - val_loss: 7.8923 - val_perplexity_raw: 1.1048\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.2991 - perplexity_raw: 1.0835 - val_loss: 7.8981 - val_perplexity_raw: 1.1048\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.2987 - perplexity_raw: 1.1043 - val_loss: 7.8985 - val_perplexity_raw: 1.1048\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.2990 - perplexity_raw: 1.0835 - val_loss: 7.8999 - val_perplexity_raw: 1.1048\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.2986 - perplexity_raw: 1.0835 - val_loss: 7.9078 - val_perplexity_raw: 1.1048\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.2990 - perplexity_raw: 1.0835 - val_loss: 7.9134 - val_perplexity_raw: 1.1048\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.2981 - perplexity_raw: 1.0835 - val_loss: 7.9192 - val_perplexity_raw: 1.1048\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.2976 - perplexity_raw: 1.0835 - val_loss: 7.9272 - val_perplexity_raw: 1.1048\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.2975 - perplexity_raw: 1.0835 - val_loss: 7.9301 - val_perplexity_raw: 1.1048\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.2977 - perplexity_raw: 1.0835 - val_loss: 7.9375 - val_perplexity_raw: 1.1048\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.2974 - perplexity_raw: 1.0835 - val_loss: 7.9434 - val_perplexity_raw: 1.1048\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.2963 - perplexity_raw: 1.0835 - val_loss: 7.9490 - val_perplexity_raw: 1.1048\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.2972 - perplexity_raw: 1.0835 - val_loss: 7.9499 - val_perplexity_raw: 1.1048\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.2955 - perplexity_raw: 1.0835 - val_loss: 7.9528 - val_perplexity_raw: 1.1048\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.2966 - perplexity_raw: 1.0835 - val_loss: 7.9583 - val_perplexity_raw: 1.1048\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.2946 - perplexity_raw: 1.0835 - val_loss: 7.9632 - val_perplexity_raw: 1.1048\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.2958 - perplexity_raw: 1.0835 - val_loss: 7.9673 - val_perplexity_raw: 1.1048\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.2962 - perplexity_raw: 1.0835 - val_loss: 7.9720 - val_perplexity_raw: 1.1048\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.2961 - perplexity_raw: 1.0974 - val_loss: 7.9775 - val_perplexity_raw: 1.1257\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.2941 - perplexity_raw: 1.1183 - val_loss: 7.9802 - val_perplexity_raw: 1.1257\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.2931 - perplexity_raw: 1.1183 - val_loss: 7.9862 - val_perplexity_raw: 1.1048\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.2953 - perplexity_raw: 1.0835 - val_loss: 7.9907 - val_perplexity_raw: 1.1048\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.2939 - perplexity_raw: 1.0835 - val_loss: 7.9965 - val_perplexity_raw: 1.1048\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.2937 - perplexity_raw: 1.0835 - val_loss: 8.0010 - val_perplexity_raw: 1.1048\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.2944 - perplexity_raw: 1.0835 - val_loss: 8.0011 - val_perplexity_raw: 1.1048\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.2923 - perplexity_raw: 1.0835 - val_loss: 8.0057 - val_perplexity_raw: 1.1048\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.2930 - perplexity_raw: 1.0835 - val_loss: 8.0122 - val_perplexity_raw: 1.1048\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.2930 - perplexity_raw: 1.0835 - val_loss: 8.0155 - val_perplexity_raw: 1.1048\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.2949 - perplexity_raw: 1.0904 - val_loss: 8.0232 - val_perplexity_raw: 1.1257\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.2929 - perplexity_raw: 1.1183 - val_loss: 8.0226 - val_perplexity_raw: 1.1257\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.2921 - perplexity_raw: 1.1183 - val_loss: 8.0243 - val_perplexity_raw: 1.1257\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.2926 - perplexity_raw: 1.1183 - val_loss: 8.0284 - val_perplexity_raw: 1.1257\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.2923 - perplexity_raw: 1.1183 - val_loss: 8.0299 - val_perplexity_raw: 1.1257\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.2920 - perplexity_raw: 1.1183 - val_loss: 8.0331 - val_perplexity_raw: 1.1257\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.2912 - perplexity_raw: 1.1043 - val_loss: 8.0396 - val_perplexity_raw: 1.1048\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.2911 - perplexity_raw: 1.0835 - val_loss: 8.0449 - val_perplexity_raw: 1.1048\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.2932 - perplexity_raw: 1.0835 - val_loss: 8.0476 - val_perplexity_raw: 1.1048\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.2937 - perplexity_raw: 1.0835 - val_loss: 8.0514 - val_perplexity_raw: 1.1048\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.2907 - perplexity_raw: 1.0835 - val_loss: 8.0517 - val_perplexity_raw: 1.1048\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.2913 - perplexity_raw: 1.0835 - val_loss: 8.0582 - val_perplexity_raw: 1.1048\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.2906 - perplexity_raw: 1.0835 - val_loss: 8.0583 - val_perplexity_raw: 1.1048\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.2903 - perplexity_raw: 1.0835 - val_loss: 8.0643 - val_perplexity_raw: 1.1048\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.2906 - perplexity_raw: 1.0835 - val_loss: 8.0676 - val_perplexity_raw: 1.1048\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.2900 - perplexity_raw: 1.0835 - val_loss: 8.0706 - val_perplexity_raw: 1.1048\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.2894 - perplexity_raw: 1.0835 - val_loss: 8.0725 - val_perplexity_raw: 1.1048\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.2916 - perplexity_raw: 1.0835 - val_loss: 8.0801 - val_perplexity_raw: 1.1048\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.2909 - perplexity_raw: 1.1043 - val_loss: 8.0815 - val_perplexity_raw: 1.1257\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.2902 - perplexity_raw: 1.1183 - val_loss: 8.0829 - val_perplexity_raw: 1.1257\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.2895 - perplexity_raw: 1.1183 - val_loss: 8.0856 - val_perplexity_raw: 1.1048\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.2894 - perplexity_raw: 1.0835 - val_loss: 8.0902 - val_perplexity_raw: 1.1048\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.2900 - perplexity_raw: 1.0835 - val_loss: 8.0942 - val_perplexity_raw: 1.1048\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.2893 - perplexity_raw: 1.0835 - val_loss: 8.0939 - val_perplexity_raw: 1.1048\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.2888 - perplexity_raw: 1.0835 - val_loss: 8.1021 - val_perplexity_raw: 1.1048\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.2889 - perplexity_raw: 1.1113 - val_loss: 8.1052 - val_perplexity_raw: 1.1257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Baseline(tokenizer=<keras_preprocessing.text.Tokenizer object at 0x7fdc6b88bba8>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Baseline()\n",
    "X_train, X_test, y_train, y_test = model.etl(data)\n",
    "print_shapes()\n",
    "model.fit(X_train, X_test, y_train, y_test, epochs=200, verbose=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (247, 6)\n",
      "Shape of X_test: (82, 6)\n",
      "Shape of y_train: (247, 194)\n",
      "Shape of y_test: (82, 194)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 6, 64)             12416     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 6, 32)             12416     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 6, 32)             8320      \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 6, 32)             8320      \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 194)               6402      \n",
      "=================================================================\n",
      "Total params: 56,194\n",
      "Trainable params: 56,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 247 samples, validate on 82 samples\n",
      "Epoch 1/200\n",
      " - 3s - loss: 5.2661 - perplexity_raw: 1.0000 - val_loss: 5.2636 - val_perplexity_raw: 1.0000\n",
      "Epoch 2/200\n",
      " - 0s - loss: 5.2567 - perplexity_raw: 1.0000 - val_loss: 5.2578 - val_perplexity_raw: 1.0000\n",
      "Epoch 3/200\n",
      " - 0s - loss: 5.2391 - perplexity_raw: 1.0000 - val_loss: 5.2430 - val_perplexity_raw: 1.0000\n",
      "Epoch 4/200\n",
      " - 0s - loss: 5.1823 - perplexity_raw: 1.0000 - val_loss: 5.1963 - val_perplexity_raw: 1.0000\n",
      "Epoch 5/200\n",
      " - 0s - loss: 5.0043 - perplexity_raw: 1.0000 - val_loss: 5.1328 - val_perplexity_raw: 1.0000\n",
      "Epoch 6/200\n",
      " - 0s - loss: 4.7749 - perplexity_raw: 1.0000 - val_loss: 5.2051 - val_perplexity_raw: 1.0000\n",
      "Epoch 7/200\n",
      " - 0s - loss: 4.6371 - perplexity_raw: 1.0000 - val_loss: 5.3473 - val_perplexity_raw: 1.0000\n",
      "Epoch 8/200\n",
      " - 0s - loss: 4.5843 - perplexity_raw: 1.0000 - val_loss: 5.4632 - val_perplexity_raw: 1.0000\n",
      "Epoch 9/200\n",
      " - 0s - loss: 4.5477 - perplexity_raw: 1.0000 - val_loss: 5.5463 - val_perplexity_raw: 1.0000\n",
      "Epoch 10/200\n",
      " - 0s - loss: 4.5236 - perplexity_raw: 1.0000 - val_loss: 5.6097 - val_perplexity_raw: 1.0000\n",
      "Epoch 11/200\n",
      " - 0s - loss: 4.5101 - perplexity_raw: 1.0000 - val_loss: 5.6624 - val_perplexity_raw: 1.0000\n",
      "Epoch 12/200\n",
      " - 0s - loss: 4.4995 - perplexity_raw: 1.0070 - val_loss: 5.7267 - val_perplexity_raw: 1.0000\n",
      "Epoch 13/200\n",
      " - 0s - loss: 4.4943 - perplexity_raw: 1.0070 - val_loss: 5.7898 - val_perplexity_raw: 1.0000\n",
      "Epoch 14/200\n",
      " - 0s - loss: 4.4871 - perplexity_raw: 1.0000 - val_loss: 5.8418 - val_perplexity_raw: 1.0000\n",
      "Epoch 15/200\n",
      " - 0s - loss: 4.4832 - perplexity_raw: 1.0000 - val_loss: 5.8963 - val_perplexity_raw: 1.0000\n",
      "Epoch 16/200\n",
      " - 0s - loss: 4.4797 - perplexity_raw: 1.0000 - val_loss: 5.9340 - val_perplexity_raw: 1.0000\n",
      "Epoch 17/200\n",
      " - 0s - loss: 4.4780 - perplexity_raw: 1.0000 - val_loss: 5.9702 - val_perplexity_raw: 1.0000\n",
      "Epoch 18/200\n",
      " - 0s - loss: 4.4764 - perplexity_raw: 1.0000 - val_loss: 6.0073 - val_perplexity_raw: 1.0000\n",
      "Epoch 19/200\n",
      " - 0s - loss: 4.4751 - perplexity_raw: 1.0000 - val_loss: 6.0446 - val_perplexity_raw: 1.0000\n",
      "Epoch 20/200\n",
      " - 0s - loss: 4.4727 - perplexity_raw: 1.0000 - val_loss: 6.0876 - val_perplexity_raw: 1.0000\n",
      "Epoch 21/200\n",
      " - 0s - loss: 4.4712 - perplexity_raw: 1.0000 - val_loss: 6.1161 - val_perplexity_raw: 1.0000\n",
      "Epoch 22/200\n",
      " - 0s - loss: 4.4698 - perplexity_raw: 1.0000 - val_loss: 6.1505 - val_perplexity_raw: 1.0000\n",
      "Epoch 23/200\n",
      " - 0s - loss: 4.4686 - perplexity_raw: 1.0000 - val_loss: 6.1838 - val_perplexity_raw: 1.0000\n",
      "Epoch 24/200\n",
      " - 0s - loss: 4.4689 - perplexity_raw: 1.0000 - val_loss: 6.2050 - val_perplexity_raw: 1.0000\n",
      "Epoch 25/200\n",
      " - 0s - loss: 4.4670 - perplexity_raw: 1.0000 - val_loss: 6.2404 - val_perplexity_raw: 1.0000\n",
      "Epoch 26/200\n",
      " - 0s - loss: 4.4665 - perplexity_raw: 1.0000 - val_loss: 6.2650 - val_perplexity_raw: 1.0000\n",
      "Epoch 27/200\n",
      " - 0s - loss: 4.4658 - perplexity_raw: 1.0000 - val_loss: 6.2844 - val_perplexity_raw: 1.0000\n",
      "Epoch 28/200\n",
      " - 0s - loss: 4.4649 - perplexity_raw: 1.0000 - val_loss: 6.3112 - val_perplexity_raw: 1.0000\n",
      "Epoch 29/200\n",
      " - 0s - loss: 4.4641 - perplexity_raw: 1.0000 - val_loss: 6.3353 - val_perplexity_raw: 1.0000\n",
      "Epoch 30/200\n",
      " - 0s - loss: 4.4639 - perplexity_raw: 1.0000 - val_loss: 6.3570 - val_perplexity_raw: 1.0000\n",
      "Epoch 31/200\n",
      " - 0s - loss: 4.4629 - perplexity_raw: 1.0000 - val_loss: 6.3778 - val_perplexity_raw: 1.0000\n",
      "Epoch 32/200\n",
      " - 0s - loss: 4.4626 - perplexity_raw: 1.0000 - val_loss: 6.3915 - val_perplexity_raw: 1.0000\n",
      "Epoch 33/200\n",
      " - 0s - loss: 4.4612 - perplexity_raw: 1.0000 - val_loss: 6.4021 - val_perplexity_raw: 1.0000\n",
      "Epoch 34/200\n",
      " - 0s - loss: 4.4594 - perplexity_raw: 1.0000 - val_loss: 6.4127 - val_perplexity_raw: 1.0000\n",
      "Epoch 35/200\n",
      " - 0s - loss: 4.4575 - perplexity_raw: 1.0000 - val_loss: 6.4251 - val_perplexity_raw: 1.0000\n",
      "Epoch 36/200\n",
      " - 0s - loss: 4.4546 - perplexity_raw: 1.0000 - val_loss: 6.4085 - val_perplexity_raw: 1.0000\n",
      "Epoch 37/200\n",
      " - 0s - loss: 4.4496 - perplexity_raw: 1.0000 - val_loss: 6.3657 - val_perplexity_raw: 1.0000\n",
      "Epoch 38/200\n",
      " - 0s - loss: 4.4411 - perplexity_raw: 1.0000 - val_loss: 6.2487 - val_perplexity_raw: 1.0000\n",
      "Epoch 39/200\n",
      " - 0s - loss: 4.4288 - perplexity_raw: 1.0070 - val_loss: 6.0877 - val_perplexity_raw: 1.0210\n",
      "Epoch 40/200\n",
      " - 0s - loss: 4.4124 - perplexity_raw: 1.0209 - val_loss: 5.9067 - val_perplexity_raw: 1.0000\n",
      "Epoch 41/200\n",
      " - 0s - loss: 4.3977 - perplexity_raw: 1.0000 - val_loss: 6.0097 - val_perplexity_raw: 1.0000\n",
      "Epoch 42/200\n",
      " - 0s - loss: 4.3864 - perplexity_raw: 1.0000 - val_loss: 5.9698 - val_perplexity_raw: 1.0000\n",
      "Epoch 43/200\n",
      " - 0s - loss: 4.3725 - perplexity_raw: 1.0000 - val_loss: 5.8813 - val_perplexity_raw: 1.0000\n",
      "Epoch 44/200\n",
      " - 0s - loss: 4.3585 - perplexity_raw: 1.0000 - val_loss: 5.8242 - val_perplexity_raw: 1.0000\n",
      "Epoch 45/200\n",
      " - 0s - loss: 4.3464 - perplexity_raw: 1.0000 - val_loss: 5.7923 - val_perplexity_raw: 1.0000\n",
      "Epoch 46/200\n",
      " - 0s - loss: 4.3378 - perplexity_raw: 1.0000 - val_loss: 5.7703 - val_perplexity_raw: 1.0000\n",
      "Epoch 47/200\n",
      " - 0s - loss: 4.3265 - perplexity_raw: 1.0000 - val_loss: 5.7972 - val_perplexity_raw: 1.0000\n",
      "Epoch 48/200\n",
      " - 0s - loss: 4.3207 - perplexity_raw: 1.0000 - val_loss: 5.8149 - val_perplexity_raw: 1.0000\n",
      "Epoch 49/200\n",
      " - 0s - loss: 4.2987 - perplexity_raw: 1.0000 - val_loss: 5.7011 - val_perplexity_raw: 1.0000\n",
      "Epoch 50/200\n",
      " - 0s - loss: 4.2844 - perplexity_raw: 1.0000 - val_loss: 5.7890 - val_perplexity_raw: 1.0000\n",
      "Epoch 51/200\n",
      " - 0s - loss: 4.2770 - perplexity_raw: 1.0000 - val_loss: 5.7197 - val_perplexity_raw: 1.0000\n",
      "Epoch 52/200\n",
      " - 0s - loss: 4.2598 - perplexity_raw: 1.0000 - val_loss: 5.6392 - val_perplexity_raw: 1.0000\n",
      "Epoch 53/200\n",
      " - 0s - loss: 4.2490 - perplexity_raw: 1.0000 - val_loss: 5.7709 - val_perplexity_raw: 1.0000\n",
      "Epoch 54/200\n",
      " - 0s - loss: 4.2342 - perplexity_raw: 1.0000 - val_loss: 5.6612 - val_perplexity_raw: 1.0000\n",
      "Epoch 55/200\n",
      " - 0s - loss: 4.2218 - perplexity_raw: 1.0000 - val_loss: 5.7229 - val_perplexity_raw: 1.0000\n",
      "Epoch 56/200\n",
      " - 0s - loss: 4.2073 - perplexity_raw: 1.0000 - val_loss: 5.6920 - val_perplexity_raw: 1.0000\n",
      "Epoch 57/200\n",
      " - 0s - loss: 4.1925 - perplexity_raw: 1.0000 - val_loss: 5.7369 - val_perplexity_raw: 1.0000\n",
      "Epoch 58/200\n",
      " - 0s - loss: 4.1799 - perplexity_raw: 1.0000 - val_loss: 5.6145 - val_perplexity_raw: 1.0000\n",
      "Epoch 59/200\n",
      " - 0s - loss: 4.1670 - perplexity_raw: 1.0000 - val_loss: 5.6775 - val_perplexity_raw: 1.0000\n",
      "Epoch 60/200\n",
      " - 0s - loss: 4.1496 - perplexity_raw: 1.0000 - val_loss: 5.7191 - val_perplexity_raw: 1.0000\n",
      "Epoch 61/200\n",
      " - 0s - loss: 4.1324 - perplexity_raw: 1.0000 - val_loss: 5.6685 - val_perplexity_raw: 1.0000\n",
      "Epoch 62/200\n",
      " - 0s - loss: 4.1115 - perplexity_raw: 1.0000 - val_loss: 5.7400 - val_perplexity_raw: 1.0000\n",
      "Epoch 63/200\n",
      " - 0s - loss: 4.0971 - perplexity_raw: 1.0000 - val_loss: 5.7724 - val_perplexity_raw: 1.0000\n",
      "Epoch 64/200\n",
      " - 0s - loss: 4.0798 - perplexity_raw: 1.0000 - val_loss: 5.8043 - val_perplexity_raw: 1.0000\n",
      "Epoch 65/200\n",
      " - 0s - loss: 4.0636 - perplexity_raw: 1.0000 - val_loss: 5.7663 - val_perplexity_raw: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200\n",
      " - 0s - loss: 4.0472 - perplexity_raw: 1.0000 - val_loss: 5.8146 - val_perplexity_raw: 1.0000\n",
      "Epoch 67/200\n",
      " - 0s - loss: 4.0317 - perplexity_raw: 1.0000 - val_loss: 5.8110 - val_perplexity_raw: 1.0000\n",
      "Epoch 68/200\n",
      " - 0s - loss: 4.0192 - perplexity_raw: 1.0000 - val_loss: 5.8578 - val_perplexity_raw: 1.0000\n",
      "Epoch 69/200\n",
      " - 0s - loss: 4.0050 - perplexity_raw: 1.0000 - val_loss: 5.9300 - val_perplexity_raw: 1.0000\n",
      "Epoch 70/200\n",
      " - 0s - loss: 3.9882 - perplexity_raw: 1.0000 - val_loss: 5.8713 - val_perplexity_raw: 1.0000\n",
      "Epoch 71/200\n",
      " - 0s - loss: 3.9693 - perplexity_raw: 1.0000 - val_loss: 5.9749 - val_perplexity_raw: 1.0000\n",
      "Epoch 72/200\n",
      " - 0s - loss: 3.9572 - perplexity_raw: 1.0000 - val_loss: 5.9155 - val_perplexity_raw: 1.0000\n",
      "Epoch 73/200\n",
      " - 0s - loss: 3.9445 - perplexity_raw: 1.0000 - val_loss: 6.0011 - val_perplexity_raw: 1.0000\n",
      "Epoch 74/200\n",
      " - 0s - loss: 3.9240 - perplexity_raw: 1.0000 - val_loss: 5.9815 - val_perplexity_raw: 1.0000\n",
      "Epoch 75/200\n",
      " - 0s - loss: 3.9054 - perplexity_raw: 1.0000 - val_loss: 6.0388 - val_perplexity_raw: 1.0000\n",
      "Epoch 76/200\n",
      " - 0s - loss: 3.8898 - perplexity_raw: 1.0000 - val_loss: 6.0374 - val_perplexity_raw: 1.0000\n",
      "Epoch 77/200\n",
      " - 0s - loss: 3.8749 - perplexity_raw: 1.0000 - val_loss: 6.0600 - val_perplexity_raw: 1.0000\n",
      "Epoch 78/200\n",
      " - 0s - loss: 3.8570 - perplexity_raw: 1.0000 - val_loss: 6.0780 - val_perplexity_raw: 1.0000\n",
      "Epoch 79/200\n",
      " - 0s - loss: 3.8413 - perplexity_raw: 1.0000 - val_loss: 6.1370 - val_perplexity_raw: 1.0000\n",
      "Epoch 80/200\n",
      " - 0s - loss: 3.8246 - perplexity_raw: 1.0000 - val_loss: 6.1289 - val_perplexity_raw: 1.0000\n",
      "Epoch 81/200\n",
      " - 0s - loss: 3.8071 - perplexity_raw: 1.0000 - val_loss: 6.1959 - val_perplexity_raw: 1.0000\n",
      "Epoch 82/200\n",
      " - 0s - loss: 3.7900 - perplexity_raw: 1.0000 - val_loss: 6.1493 - val_perplexity_raw: 1.0000\n",
      "Epoch 83/200\n",
      " - 0s - loss: 3.7739 - perplexity_raw: 1.0000 - val_loss: 6.1837 - val_perplexity_raw: 1.0000\n",
      "Epoch 84/200\n",
      " - 0s - loss: 3.7541 - perplexity_raw: 1.0000 - val_loss: 6.1965 - val_perplexity_raw: 1.0000\n",
      "Epoch 85/200\n",
      " - 0s - loss: 3.7370 - perplexity_raw: 1.0000 - val_loss: 6.1956 - val_perplexity_raw: 1.0000\n",
      "Epoch 86/200\n",
      " - 0s - loss: 3.7205 - perplexity_raw: 1.0000 - val_loss: 6.2526 - val_perplexity_raw: 1.0000\n",
      "Epoch 87/200\n",
      " - 0s - loss: 3.7046 - perplexity_raw: 1.0000 - val_loss: 6.2638 - val_perplexity_raw: 1.0000\n",
      "Epoch 88/200\n",
      " - 0s - loss: 3.6869 - perplexity_raw: 1.0000 - val_loss: 6.2719 - val_perplexity_raw: 1.0000\n",
      "Epoch 89/200\n",
      " - 0s - loss: 3.6697 - perplexity_raw: 1.0000 - val_loss: 6.2365 - val_perplexity_raw: 1.0000\n",
      "Epoch 90/200\n",
      " - 0s - loss: 3.6547 - perplexity_raw: 1.0000 - val_loss: 6.3086 - val_perplexity_raw: 1.0000\n",
      "Epoch 91/200\n",
      " - 0s - loss: 3.6392 - perplexity_raw: 1.0000 - val_loss: 6.3393 - val_perplexity_raw: 1.0000\n",
      "Epoch 92/200\n",
      " - 0s - loss: 3.6274 - perplexity_raw: 1.0000 - val_loss: 6.3347 - val_perplexity_raw: 1.0000\n",
      "Epoch 93/200\n",
      " - 0s - loss: 3.6107 - perplexity_raw: 1.0070 - val_loss: 6.3387 - val_perplexity_raw: 1.0000\n",
      "Epoch 94/200\n",
      " - 0s - loss: 3.5910 - perplexity_raw: 1.0000 - val_loss: 6.3436 - val_perplexity_raw: 1.0000\n",
      "Epoch 95/200\n",
      " - 0s - loss: 3.5723 - perplexity_raw: 1.0000 - val_loss: 6.3304 - val_perplexity_raw: 1.0000\n",
      "Epoch 96/200\n",
      " - 0s - loss: 3.5574 - perplexity_raw: 1.0070 - val_loss: 6.3518 - val_perplexity_raw: 1.0000\n",
      "Epoch 97/200\n",
      " - 0s - loss: 3.5418 - perplexity_raw: 1.0000 - val_loss: 6.4199 - val_perplexity_raw: 1.0000\n",
      "Epoch 98/200\n",
      " - 0s - loss: 3.5269 - perplexity_raw: 1.0000 - val_loss: 6.3833 - val_perplexity_raw: 1.0000\n",
      "Epoch 99/200\n",
      " - 0s - loss: 3.5108 - perplexity_raw: 1.0000 - val_loss: 6.4762 - val_perplexity_raw: 1.0000\n",
      "Epoch 100/200\n",
      " - 0s - loss: 3.4986 - perplexity_raw: 1.0000 - val_loss: 6.4344 - val_perplexity_raw: 1.0000\n",
      "Epoch 101/200\n",
      " - 0s - loss: 3.4859 - perplexity_raw: 1.0000 - val_loss: 6.4711 - val_perplexity_raw: 1.0000\n",
      "Epoch 102/200\n",
      " - 0s - loss: 3.4714 - perplexity_raw: 1.0070 - val_loss: 6.4462 - val_perplexity_raw: 1.0000\n",
      "Epoch 103/200\n",
      " - 0s - loss: 3.4556 - perplexity_raw: 1.0070 - val_loss: 6.4925 - val_perplexity_raw: 1.0000\n",
      "Epoch 104/200\n",
      " - 0s - loss: 3.4470 - perplexity_raw: 1.0000 - val_loss: 6.5246 - val_perplexity_raw: 1.0000\n",
      "Epoch 105/200\n",
      " - 0s - loss: 3.4401 - perplexity_raw: 1.0000 - val_loss: 6.5164 - val_perplexity_raw: 1.0000\n",
      "Epoch 106/200\n",
      " - 0s - loss: 3.4225 - perplexity_raw: 1.0070 - val_loss: 6.5202 - val_perplexity_raw: 1.0000\n",
      "Epoch 107/200\n",
      " - 0s - loss: 3.4059 - perplexity_raw: 1.0070 - val_loss: 6.5326 - val_perplexity_raw: 1.0000\n",
      "Epoch 108/200\n",
      " - 0s - loss: 3.4006 - perplexity_raw: 1.0000 - val_loss: 6.6032 - val_perplexity_raw: 1.0000\n",
      "Epoch 109/200\n",
      " - 0s - loss: 3.3861 - perplexity_raw: 1.0070 - val_loss: 6.5455 - val_perplexity_raw: 1.0000\n",
      "Epoch 110/200\n",
      " - 0s - loss: 3.3757 - perplexity_raw: 1.0070 - val_loss: 6.5683 - val_perplexity_raw: 1.0000\n",
      "Epoch 111/200\n",
      " - 0s - loss: 3.3558 - perplexity_raw: 1.0139 - val_loss: 6.6037 - val_perplexity_raw: 1.0000\n",
      "Epoch 112/200\n",
      " - 0s - loss: 3.3400 - perplexity_raw: 1.0000 - val_loss: 6.6001 - val_perplexity_raw: 1.0000\n",
      "Epoch 113/200\n",
      " - 0s - loss: 3.3278 - perplexity_raw: 1.0139 - val_loss: 6.5863 - val_perplexity_raw: 1.0000\n",
      "Epoch 114/200\n",
      " - 0s - loss: 3.3151 - perplexity_raw: 1.0070 - val_loss: 6.6351 - val_perplexity_raw: 1.0000\n",
      "Epoch 115/200\n",
      " - 0s - loss: 3.3052 - perplexity_raw: 1.0070 - val_loss: 6.6103 - val_perplexity_raw: 1.0000\n",
      "Epoch 116/200\n",
      " - 0s - loss: 3.2900 - perplexity_raw: 1.0139 - val_loss: 6.6502 - val_perplexity_raw: 1.0000\n",
      "Epoch 117/200\n",
      " - 0s - loss: 3.2773 - perplexity_raw: 1.0209 - val_loss: 6.6527 - val_perplexity_raw: 1.0000\n",
      "Epoch 118/200\n",
      " - 0s - loss: 3.2611 - perplexity_raw: 1.0070 - val_loss: 6.6748 - val_perplexity_raw: 1.0000\n",
      "Epoch 119/200\n",
      " - 0s - loss: 3.2490 - perplexity_raw: 1.0139 - val_loss: 6.6641 - val_perplexity_raw: 1.0000\n",
      "Epoch 120/200\n",
      " - 0s - loss: 3.2363 - perplexity_raw: 1.0209 - val_loss: 6.6946 - val_perplexity_raw: 1.0000\n",
      "Epoch 121/200\n",
      " - 0s - loss: 3.2254 - perplexity_raw: 1.0070 - val_loss: 6.7037 - val_perplexity_raw: 1.0000\n",
      "Epoch 122/200\n",
      " - 0s - loss: 3.2166 - perplexity_raw: 1.0139 - val_loss: 6.6940 - val_perplexity_raw: 1.0000\n",
      "Epoch 123/200\n",
      " - 0s - loss: 3.2047 - perplexity_raw: 1.0209 - val_loss: 6.6864 - val_perplexity_raw: 1.0000\n",
      "Epoch 124/200\n",
      " - 0s - loss: 3.1952 - perplexity_raw: 1.0139 - val_loss: 6.7343 - val_perplexity_raw: 1.0000\n",
      "Epoch 125/200\n",
      " - 0s - loss: 3.1833 - perplexity_raw: 1.0070 - val_loss: 6.7140 - val_perplexity_raw: 1.0000\n",
      "Epoch 126/200\n",
      " - 0s - loss: 3.1674 - perplexity_raw: 1.0139 - val_loss: 6.7064 - val_perplexity_raw: 1.0000\n",
      "Epoch 127/200\n",
      " - 0s - loss: 3.1577 - perplexity_raw: 1.0139 - val_loss: 6.7450 - val_perplexity_raw: 1.0000\n",
      "Epoch 128/200\n",
      " - 0s - loss: 3.1497 - perplexity_raw: 1.0139 - val_loss: 6.6999 - val_perplexity_raw: 1.0000\n",
      "Epoch 129/200\n",
      " - 0s - loss: 3.1337 - perplexity_raw: 1.0070 - val_loss: 6.7465 - val_perplexity_raw: 1.0000\n",
      "Epoch 130/200\n",
      " - 0s - loss: 3.1262 - perplexity_raw: 1.0139 - val_loss: 6.7181 - val_perplexity_raw: 1.0000\n",
      "Epoch 131/200\n",
      " - 0s - loss: 3.1115 - perplexity_raw: 1.0209 - val_loss: 6.7657 - val_perplexity_raw: 1.0000\n",
      "Epoch 132/200\n",
      " - 0s - loss: 3.0999 - perplexity_raw: 1.0209 - val_loss: 6.7602 - val_perplexity_raw: 1.0000\n",
      "Epoch 133/200\n",
      " - 0s - loss: 3.0848 - perplexity_raw: 1.0209 - val_loss: 6.7586 - val_perplexity_raw: 1.0000\n",
      "Epoch 134/200\n",
      " - 0s - loss: 3.0813 - perplexity_raw: 1.0139 - val_loss: 6.7642 - val_perplexity_raw: 1.0000\n",
      "Epoch 135/200\n",
      " - 0s - loss: 3.0723 - perplexity_raw: 1.0139 - val_loss: 6.7421 - val_perplexity_raw: 1.0000\n",
      "Epoch 136/200\n",
      " - 0s - loss: 3.0664 - perplexity_raw: 1.0139 - val_loss: 6.8246 - val_perplexity_raw: 1.0210\n",
      "Epoch 137/200\n",
      " - 0s - loss: 3.0677 - perplexity_raw: 1.0348 - val_loss: 6.7843 - val_perplexity_raw: 1.0000\n",
      "Epoch 138/200\n",
      " - 0s - loss: 3.0539 - perplexity_raw: 1.0070 - val_loss: 6.8338 - val_perplexity_raw: 1.0000\n",
      "Epoch 139/200\n",
      " - 0s - loss: 3.0346 - perplexity_raw: 1.0000 - val_loss: 6.7590 - val_perplexity_raw: 1.0000\n",
      "Epoch 140/200\n",
      " - 0s - loss: 3.0303 - perplexity_raw: 1.0070 - val_loss: 6.7790 - val_perplexity_raw: 1.0000\n",
      "Epoch 141/200\n",
      " - 0s - loss: 3.0131 - perplexity_raw: 1.0139 - val_loss: 6.8329 - val_perplexity_raw: 1.0000\n",
      "Epoch 142/200\n",
      " - 0s - loss: 3.0022 - perplexity_raw: 1.0070 - val_loss: 6.8318 - val_perplexity_raw: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/200\n",
      " - 0s - loss: 2.9955 - perplexity_raw: 1.0139 - val_loss: 6.7908 - val_perplexity_raw: 1.0000\n",
      "Epoch 144/200\n",
      " - 0s - loss: 2.9808 - perplexity_raw: 1.0139 - val_loss: 6.8196 - val_perplexity_raw: 1.0000\n",
      "Epoch 145/200\n",
      " - 0s - loss: 2.9695 - perplexity_raw: 1.0000 - val_loss: 6.8332 - val_perplexity_raw: 1.0000\n",
      "Epoch 146/200\n",
      " - 0s - loss: 2.9570 - perplexity_raw: 1.0070 - val_loss: 6.8580 - val_perplexity_raw: 1.0000\n",
      "Epoch 147/200\n",
      " - 0s - loss: 2.9457 - perplexity_raw: 1.0070 - val_loss: 6.8324 - val_perplexity_raw: 1.0000\n",
      "Epoch 148/200\n",
      " - 0s - loss: 2.9361 - perplexity_raw: 1.0139 - val_loss: 6.8477 - val_perplexity_raw: 1.0000\n",
      "Epoch 149/200\n",
      " - 0s - loss: 2.9249 - perplexity_raw: 1.0139 - val_loss: 6.8482 - val_perplexity_raw: 1.0000\n",
      "Epoch 150/200\n",
      " - 0s - loss: 2.9130 - perplexity_raw: 1.0070 - val_loss: 6.9067 - val_perplexity_raw: 1.0000\n",
      "Epoch 151/200\n",
      " - 0s - loss: 2.9064 - perplexity_raw: 1.0139 - val_loss: 6.8599 - val_perplexity_raw: 1.0000\n",
      "Epoch 152/200\n",
      " - 0s - loss: 2.9008 - perplexity_raw: 1.0139 - val_loss: 6.8769 - val_perplexity_raw: 1.0000\n",
      "Epoch 153/200\n",
      " - 0s - loss: 2.8943 - perplexity_raw: 1.0139 - val_loss: 6.8076 - val_perplexity_raw: 1.0000\n",
      "Epoch 154/200\n",
      " - 0s - loss: 2.8908 - perplexity_raw: 1.0139 - val_loss: 6.9081 - val_perplexity_raw: 1.0000\n",
      "Epoch 155/200\n",
      " - 0s - loss: 2.8773 - perplexity_raw: 1.0070 - val_loss: 6.9034 - val_perplexity_raw: 1.0000\n",
      "Epoch 156/200\n",
      " - 0s - loss: 2.8687 - perplexity_raw: 1.0139 - val_loss: 6.9028 - val_perplexity_raw: 1.0000\n",
      "Epoch 157/200\n",
      " - 0s - loss: 2.8578 - perplexity_raw: 1.0070 - val_loss: 6.8315 - val_perplexity_raw: 1.0000\n",
      "Epoch 158/200\n",
      " - 0s - loss: 2.8497 - perplexity_raw: 1.0139 - val_loss: 6.9650 - val_perplexity_raw: 1.0000\n",
      "Epoch 159/200\n",
      " - 0s - loss: 2.8415 - perplexity_raw: 1.0070 - val_loss: 6.8674 - val_perplexity_raw: 1.0000\n",
      "Epoch 160/200\n",
      " - 0s - loss: 2.8296 - perplexity_raw: 1.0139 - val_loss: 6.8961 - val_perplexity_raw: 1.0000\n",
      "Epoch 161/200\n",
      " - 0s - loss: 2.8176 - perplexity_raw: 1.0209 - val_loss: 6.8919 - val_perplexity_raw: 1.0000\n",
      "Epoch 162/200\n",
      " - 0s - loss: 2.8051 - perplexity_raw: 1.0139 - val_loss: 6.9226 - val_perplexity_raw: 1.0000\n",
      "Epoch 163/200\n",
      " - 0s - loss: 2.7938 - perplexity_raw: 1.0139 - val_loss: 6.9170 - val_perplexity_raw: 1.0000\n",
      "Epoch 164/200\n",
      " - 0s - loss: 2.7807 - perplexity_raw: 1.0139 - val_loss: 6.9411 - val_perplexity_raw: 1.0000\n",
      "Epoch 165/200\n",
      " - 0s - loss: 2.7741 - perplexity_raw: 1.0139 - val_loss: 6.9161 - val_perplexity_raw: 1.0000\n",
      "Epoch 166/200\n",
      " - 0s - loss: 2.7616 - perplexity_raw: 1.0139 - val_loss: 6.9762 - val_perplexity_raw: 1.0000\n",
      "Epoch 167/200\n",
      " - 0s - loss: 2.7606 - perplexity_raw: 1.0139 - val_loss: 6.9507 - val_perplexity_raw: 1.0000\n",
      "Epoch 168/200\n",
      " - 0s - loss: 2.7612 - perplexity_raw: 1.0139 - val_loss: 6.9342 - val_perplexity_raw: 1.0000\n",
      "Epoch 169/200\n",
      " - 0s - loss: 2.7644 - perplexity_raw: 1.0070 - val_loss: 6.9420 - val_perplexity_raw: 1.0000\n",
      "Epoch 170/200\n",
      " - 0s - loss: 2.7376 - perplexity_raw: 1.0139 - val_loss: 6.9626 - val_perplexity_raw: 1.0000\n",
      "Epoch 171/200\n",
      " - 0s - loss: 2.7305 - perplexity_raw: 1.0139 - val_loss: 6.9419 - val_perplexity_raw: 1.0000\n",
      "Epoch 172/200\n",
      " - 0s - loss: 2.7182 - perplexity_raw: 1.0070 - val_loss: 6.9927 - val_perplexity_raw: 1.0000\n",
      "Epoch 173/200\n",
      " - 0s - loss: 2.7127 - perplexity_raw: 1.0139 - val_loss: 6.9373 - val_perplexity_raw: 1.0000\n",
      "Epoch 174/200\n",
      " - 0s - loss: 2.7104 - perplexity_raw: 1.0070 - val_loss: 6.9989 - val_perplexity_raw: 1.0000\n",
      "Epoch 175/200\n",
      " - 0s - loss: 2.7104 - perplexity_raw: 1.0070 - val_loss: 6.9374 - val_perplexity_raw: 1.0000\n",
      "Epoch 176/200\n",
      " - 0s - loss: 2.7069 - perplexity_raw: 1.0000 - val_loss: 7.0457 - val_perplexity_raw: 1.0000\n",
      "Epoch 177/200\n",
      " - 0s - loss: 2.6900 - perplexity_raw: 1.0000 - val_loss: 7.0189 - val_perplexity_raw: 1.0000\n",
      "Epoch 178/200\n",
      " - 0s - loss: 2.6815 - perplexity_raw: 1.0000 - val_loss: 6.9658 - val_perplexity_raw: 1.0000\n",
      "Epoch 179/200\n",
      " - 0s - loss: 2.6607 - perplexity_raw: 1.0139 - val_loss: 6.9952 - val_perplexity_raw: 1.0000\n",
      "Epoch 180/200\n",
      " - 0s - loss: 2.6473 - perplexity_raw: 1.0000 - val_loss: 7.0002 - val_perplexity_raw: 1.0000\n",
      "Epoch 181/200\n",
      " - 0s - loss: 2.6351 - perplexity_raw: 1.0000 - val_loss: 7.0091 - val_perplexity_raw: 1.0000\n",
      "Epoch 182/200\n",
      " - 0s - loss: 2.6256 - perplexity_raw: 1.0000 - val_loss: 7.0149 - val_perplexity_raw: 1.0000\n",
      "Epoch 183/200\n",
      " - 0s - loss: 2.6169 - perplexity_raw: 1.0000 - val_loss: 7.0367 - val_perplexity_raw: 1.0000\n",
      "Epoch 184/200\n",
      " - 0s - loss: 2.6097 - perplexity_raw: 1.0000 - val_loss: 6.9964 - val_perplexity_raw: 1.0000\n",
      "Epoch 185/200\n",
      " - 0s - loss: 2.6143 - perplexity_raw: 1.0000 - val_loss: 7.0100 - val_perplexity_raw: 1.0000\n",
      "Epoch 186/200\n",
      " - 0s - loss: 2.6049 - perplexity_raw: 1.0000 - val_loss: 7.0018 - val_perplexity_raw: 1.0000\n",
      "Epoch 187/200\n",
      " - 0s - loss: 2.6013 - perplexity_raw: 1.0000 - val_loss: 7.0209 - val_perplexity_raw: 1.0000\n",
      "Epoch 188/200\n",
      " - 0s - loss: 2.5825 - perplexity_raw: 1.0000 - val_loss: 7.0079 - val_perplexity_raw: 1.0000\n",
      "Epoch 189/200\n",
      " - 0s - loss: 2.5746 - perplexity_raw: 1.0000 - val_loss: 7.0680 - val_perplexity_raw: 1.0000\n",
      "Epoch 190/200\n",
      " - 0s - loss: 2.5709 - perplexity_raw: 1.0000 - val_loss: 6.9965 - val_perplexity_raw: 1.0000\n",
      "Epoch 191/200\n",
      " - 0s - loss: 2.5591 - perplexity_raw: 1.0070 - val_loss: 7.0455 - val_perplexity_raw: 1.0000\n",
      "Epoch 192/200\n",
      " - 0s - loss: 2.5480 - perplexity_raw: 1.0000 - val_loss: 7.0807 - val_perplexity_raw: 1.0000\n",
      "Epoch 193/200\n",
      " - 0s - loss: 2.5374 - perplexity_raw: 1.0000 - val_loss: 7.0114 - val_perplexity_raw: 1.0000\n",
      "Epoch 194/200\n",
      " - 0s - loss: 2.5307 - perplexity_raw: 1.0070 - val_loss: 7.0718 - val_perplexity_raw: 1.0000\n",
      "Epoch 195/200\n",
      " - 0s - loss: 2.5224 - perplexity_raw: 1.0000 - val_loss: 7.0513 - val_perplexity_raw: 1.0000\n",
      "Epoch 196/200\n",
      " - 0s - loss: 2.5071 - perplexity_raw: 1.0000 - val_loss: 7.0600 - val_perplexity_raw: 1.0000\n",
      "Epoch 197/200\n",
      " - 0s - loss: 2.5006 - perplexity_raw: 1.0000 - val_loss: 7.0699 - val_perplexity_raw: 1.0000\n",
      "Epoch 198/200\n",
      " - 0s - loss: 2.4920 - perplexity_raw: 1.0000 - val_loss: 7.0686 - val_perplexity_raw: 1.0000\n",
      "Epoch 199/200\n",
      " - 0s - loss: 2.4838 - perplexity_raw: 1.0000 - val_loss: 7.0732 - val_perplexity_raw: 1.0000\n",
      "Epoch 200/200\n",
      " - 0s - loss: 2.4805 - perplexity_raw: 1.0000 - val_loss: 7.0598 - val_perplexity_raw: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM_Embedding(tokenizer=<keras_preprocessing.text.Tokenizer object at 0x7fdc6b88bba8>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM_Embedding()\n",
    "X_train, X_test, y_train, y_test = model.etl(data)\n",
    "print_shapes()\n",
    "model.fit(X_train, X_test, y_train, y_test, epochs=200, hidden_lstm=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
