{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTO 1\n",
    "\n",
    "* Métrica Perplejidad: https://en.wikipedia.org/wiki/Perplexity#cite_ref-1\n",
    "\n",
    "* Loss: Categorical Crossentropy (buscar más referencias para ambos)\n",
    "\n",
    "Para la memoria usar notebook como info basica e ir ampliando explicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@InProceedings{Danescu-Niculescu-Mizil+Lee:11a,\n",
    "\n",
    "  author={Cristian Danescu-Niculescu-Mizil and Lillian Lee},\n",
    "\n",
    "  title={Chameleons in imagined conversations:\n",
    "\n",
    "  A new approach to understanding coordination of linguistic style in dialogs.},\n",
    "\n",
    "  booktitle={Proceedings of the\n",
    "\n",
    "        Workshop on Cognitive Modeling and Computational Linguistics, ACL 2011},\n",
    "\n",
    "  year={2011}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3,1\"  # specify which GPU(s) to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from src.model import BaseNetwork\n",
    "from src.utils import print_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"data/movie_lines.txt\", \"rb\").read()[:1_000_000].decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (125520, 206)\n",
      "Shape of X_test: (41839, 206)\n",
      "Shape of y_train: (125520, 11502)\n",
      "Shape of y_test: (41839, 11502)\n"
     ]
    }
   ],
   "source": [
    "model = BaseNetwork(max_sequence_len=301)\n",
    "X_train, X_test, y_train, y_test = model.etl(data)\n",
    "print_shapes(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subir lstm_units, epochs 100\n",
    "# TODO: En la etl en vez de hacer lower y ya, usar spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding file loaded sucessfully!\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 206, 300)          3450600   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                85504     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11502)             747630    \n",
      "=================================================================\n",
      "Total params: 4,283,734\n",
      "Trainable params: 833,134\n",
      "Non-trainable params: 3,450,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "The fit process is starting!\n",
      "Train on 125520 samples, validate on 41839 samples\n",
      "Epoch 1/5\n",
      "125520/125520 [==============================] - 267s 2ms/step - loss: 6.5482 - perplexity_raw: 1.7850 - val_loss: 6.2953 - val_perplexity_raw: 1.3444\n",
      "Epoch 2/5\n",
      "125520/125520 [==============================] - 264s 2ms/step - loss: 5.9758 - perplexity_raw: 1.2306 - val_loss: 6.0918 - val_perplexity_raw: 1.1762\n",
      "Epoch 3/5\n",
      "125520/125520 [==============================] - 262s 2ms/step - loss: 5.7150 - perplexity_raw: 1.1924 - val_loss: 5.9833 - val_perplexity_raw: 1.1645\n",
      "Epoch 4/5\n",
      "125520/125520 [==============================] - 264s 2ms/step - loss: 5.5389 - perplexity_raw: 1.1805 - val_loss: 5.9197 - val_perplexity_raw: 1.1487\n",
      "Epoch 5/5\n",
      "125520/125520 [==============================] - 264s 2ms/step - loss: 5.4066 - perplexity_raw: 1.1725 - val_loss: 5.8817 - val_perplexity_raw: 1.1529\n"
     ]
    }
   ],
   "source": [
    "model.compile(arch=\"LSTM_Embedding\", embedding=\"fastText\", gpu=True, hidden_lstm=0, lstm_units=32)\n",
    "model.fit(X_train, X_test, y_train, y_test, epochs=5, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bianca is coming xD in the world and the country and you have to be this thing as the the way i went to see you you know it was here to be the fire you got to be in my one of the face of the whole d u s u are not here and the other of the country is a few of the job of the world is the army on the team of the world is in the center of the end of the the the world is the honor of the world is that your gun in the world is the most of it comes in the world and i know what you can do i have to say to me you like you i have a different and i know you you know the truth about the the way to send it to a girl in the the world your down to the world they are going to be a man in the door with the world you do we have a lot of the men on the world in the world the mother the world is a good in a man to do that your own daughter'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"Bianca is coming xD\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good morning the same little thing is'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"Good morning\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bianca good morning what are you think it'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"bianca good morning\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"John, I'm only dancin'! a good cop on the\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"John, I'm only dancin'!\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey you know what did you know that i have to be'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"hey you\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know me the way you can know what you know it\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"I don't know\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Wait you're not a dead for a man of it i\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"Wait\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hasta la vista rhod in a guy with a fucking fellow of the same day i happened to you think what you have'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"Hasta la vista\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Baby i know the truth i'm not not not and this is a few times but i have a lot of\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"Baby\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brother lady is a little good woman of the best of you never have to to use us to the fucking'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"Brother\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bro you i don't know it was a lot of it about the men you got to be a little good\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"Bro\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I will not go to prison the way i know you know what you know it you're not a upset of you don't know what we\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"I will not go to prison\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what about now what you think you know what you want to do to me to take me to have to do that'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"what about now\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bianca is coming xD nbianca well nbianca okay i 'd like to get ncameron i 'd like to get out of living here ncameron just do the matter where 'd your friend ncameron no nbianca i 'm workin ' ncameron she had to get out of date ncameron no no i had to go to the ncameron she 'd like to see a job ncameron she 'd nbianca what the matter is that my coiffure nbianca blonde your f friend of this crap ncameron you know nbianca i 'll go out to the ncameron i 'm not nbianca well i 'm here nbianca i 'll get out of living here nbianca no i 'll give it a woman she seemed to go nbianca well i think i 'll get to lie now i 'll go out of a few years nbianca thank you think nbianca ncameron she 'd ncameron what ncameron she 'd ncameron a man ncameron how 's the matter ncameron i 'm workin ' ncameron i 'd like to go out on my career now nbianca what do you think nbianca i 'm not nbianca well i had a pretty good message to get out there i 'll go to your fear\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"Bianca is coming xD\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good morning nbianca not even wonder nbianca'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"Good morning\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nbianca good morning did you wonder nbianca she'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"nbianca good morning\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"John, I'm only dancin'! one know what the death\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"John, I'm only dancin'!\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hey you gonna pay to steal what i 'll quit the tour\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"hey you\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I dont' know nbianca let 's go nbianca nbianca what 's matter '\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"I dont' know\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wait where the boys the need one one of a death'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"Wait\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
