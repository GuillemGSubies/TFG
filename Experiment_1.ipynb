{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTO 1\n",
    "\n",
    "* Métrica Perplejidad: https://en.wikipedia.org/wiki/Perplexity#cite_ref-1\n",
    "\n",
    "* Loss: Categorical Crossentropy (buscar más referencias para ambos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@InProceedings{Danescu-Niculescu-Mizil+Lee:11a,\n",
    "\n",
    "  author={Cristian Danescu-Niculescu-Mizil and Lillian Lee},\n",
    "\n",
    "  title={Chameleons in imagined conversations:\n",
    "\n",
    "  A new approach to understanding coordination of linguistic style in dialogs.},\n",
    "\n",
    "  booktitle={Proceedings of the\n",
    "\n",
    "        Workshop on Cognitive Modeling and Computational Linguistics, ACL 2011},\n",
    "\n",
    "  year={2011}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from src.model import BaseNetwork\n",
    "# Need to update CUDA in order to use GPU, so I disable this\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_shapes():\n",
    "    print(f\"Shape of X_train: {X_train.shape}\")\n",
    "    print(f\"Shape of X_test: {X_test.shape}\")\n",
    "    print(f\"Shape of y_train: {y_train.shape}\")\n",
    "    print(f\"Shape of y_test: {y_test.shape}\")\n",
    "    assert X_train.shape[0] == y_train.shape[0]\n",
    "    assert X_test.shape[0] == y_test.shape[0]\n",
    "    assert X_train.shape[1] == X_test.shape[1]\n",
    "    assert y_train.shape[1] == y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = str(open(\"data/movie_lines.txt\", \"rb\").read())[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (694, 925)\n",
      "Shape of X_test: (231, 925)\n",
      "Shape of y_train: (694, 350)\n",
      "Shape of y_test: (231, 350)\n"
     ]
    }
   ],
   "source": [
    "model = BaseNetwork()\n",
    "X_train, X_test, y_train, y_test = model.etl(data)\n",
    "print_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 925, 64)           22400     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 59200)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 350)               20720350  \n",
      "=================================================================\n",
      "Total params: 20,742,750\n",
      "Trainable params: 20,742,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 694 samples, validate on 231 samples\n",
      "Epoch 1/20\n",
      " - 13s - loss: 5.9752 - perplexity_raw: 1.1263 - val_loss: 5.8395 - val_perplexity_raw: 1.0000\n",
      "Epoch 2/20\n",
      " - 12s - loss: 2.7134 - perplexity_raw: 1.2377 - val_loss: 6.2982 - val_perplexity_raw: 2.5770\n",
      "Epoch 3/20\n",
      " - 12s - loss: 0.8724 - perplexity_raw: 1.1807 - val_loss: 6.4400 - val_perplexity_raw: 1.9372\n",
      "Epoch 4/20\n",
      " - 12s - loss: 0.3802 - perplexity_raw: 1.1263 - val_loss: 6.6261 - val_perplexity_raw: 2.1753\n",
      "Epoch 5/20\n",
      " - 12s - loss: 0.2189 - perplexity_raw: 1.1065 - val_loss: 6.7662 - val_perplexity_raw: 1.6695\n",
      "Epoch 6/20\n",
      " - 12s - loss: 0.1416 - perplexity_raw: 1.1238 - val_loss: 6.8789 - val_perplexity_raw: 1.9521\n",
      "Epoch 7/20\n",
      " - 12s - loss: 0.1034 - perplexity_raw: 1.0916 - val_loss: 6.8987 - val_perplexity_raw: 1.7364\n",
      "Epoch 8/20\n",
      " - 12s - loss: 0.0755 - perplexity_raw: 1.0990 - val_loss: 6.9339 - val_perplexity_raw: 1.9968\n",
      "Epoch 9/20\n",
      " - 12s - loss: 0.0557 - perplexity_raw: 1.0916 - val_loss: 6.9595 - val_perplexity_raw: 1.7141\n",
      "Epoch 10/20\n",
      " - 12s - loss: 0.0405 - perplexity_raw: 1.0916 - val_loss: 7.0114 - val_perplexity_raw: 1.9372\n",
      "Epoch 11/20\n",
      " - 12s - loss: 0.0314 - perplexity_raw: 1.0916 - val_loss: 7.0184 - val_perplexity_raw: 1.7513\n",
      "Epoch 12/20\n",
      " - 12s - loss: 0.0228 - perplexity_raw: 1.0916 - val_loss: 7.0415 - val_perplexity_raw: 1.9001\n",
      "Epoch 13/20\n",
      " - 11s - loss: 0.0198 - perplexity_raw: 1.0916 - val_loss: 7.0519 - val_perplexity_raw: 1.6843\n",
      "Epoch 14/20\n",
      " - 11s - loss: 0.0153 - perplexity_raw: 1.0916 - val_loss: 7.0822 - val_perplexity_raw: 1.7587\n",
      "Epoch 15/20\n",
      " - 12s - loss: 0.0122 - perplexity_raw: 1.0916 - val_loss: 7.0851 - val_perplexity_raw: 1.8108\n",
      "Epoch 16/20\n",
      " - 11s - loss: 0.0105 - perplexity_raw: 1.0916 - val_loss: 7.0942 - val_perplexity_raw: 1.7662\n",
      "Epoch 17/20\n",
      " - 12s - loss: 0.0091 - perplexity_raw: 1.0916 - val_loss: 7.1148 - val_perplexity_raw: 1.7215\n",
      "Epoch 18/20\n",
      " - 13s - loss: 0.0069 - perplexity_raw: 1.0916 - val_loss: 7.1210 - val_perplexity_raw: 1.6695\n",
      "Epoch 19/20\n",
      " - 13s - loss: 0.0057 - perplexity_raw: 1.0916 - val_loss: 7.1309 - val_perplexity_raw: 1.8331\n",
      "Epoch 20/20\n",
      " - 12s - loss: 0.0051 - perplexity_raw: 1.0916 - val_loss: 7.1530 - val_perplexity_raw: 1.7438\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, X_test, y_train, y_test, arch=\"Baseline\", epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 925, 64)           22400     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 925, 32)           12416     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 350)               11550     \n",
      "=================================================================\n",
      "Total params: 54,686\n",
      "Trainable params: 54,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 694 samples, validate on 231 samples\n",
      "Epoch 1/20\n",
      " - 21s - loss: 5.8515 - perplexity_raw: 1.0124 - val_loss: 5.8431 - val_perplexity_raw: 1.0372\n",
      "Epoch 2/20\n",
      " - 35s - loss: 5.6914 - perplexity_raw: 1.0099 - val_loss: 5.6870 - val_perplexity_raw: 1.0000\n",
      "Epoch 3/20\n",
      " - 48s - loss: 5.2865 - perplexity_raw: 1.8468 - val_loss: 5.7606 - val_perplexity_raw: 2.7183\n",
      "Epoch 4/20\n",
      " - 43s - loss: 5.1306 - perplexity_raw: 2.7183 - val_loss: 5.8949 - val_perplexity_raw: 2.7183\n",
      "Epoch 5/20\n",
      " - 23s - loss: 5.1007 - perplexity_raw: 2.7183 - val_loss: 5.9611 - val_perplexity_raw: 2.7183\n",
      "Epoch 6/20\n",
      " - 22s - loss: 5.0872 - perplexity_raw: 2.7183 - val_loss: 6.0245 - val_perplexity_raw: 2.7183\n",
      "Epoch 7/20\n",
      " - 33s - loss: 5.0805 - perplexity_raw: 2.7183 - val_loss: 6.0724 - val_perplexity_raw: 2.7183\n",
      "Epoch 8/20\n",
      " - 28s - loss: 5.0757 - perplexity_raw: 2.7183 - val_loss: 6.1135 - val_perplexity_raw: 2.7183\n",
      "Epoch 9/20\n",
      " - 20s - loss: 5.0733 - perplexity_raw: 2.7183 - val_loss: 6.1588 - val_perplexity_raw: 2.7183\n",
      "Epoch 10/20\n",
      " - 21s - loss: 5.0708 - perplexity_raw: 2.7183 - val_loss: 6.1934 - val_perplexity_raw: 2.7183\n",
      "Epoch 11/20\n",
      " - 22s - loss: 5.0687 - perplexity_raw: 2.7183 - val_loss: 6.2344 - val_perplexity_raw: 2.7183\n",
      "Epoch 12/20\n",
      " - 21s - loss: 5.0678 - perplexity_raw: 2.7183 - val_loss: 6.2644 - val_perplexity_raw: 2.7183\n",
      "Epoch 13/20\n",
      " - 21s - loss: 5.0665 - perplexity_raw: 2.7183 - val_loss: 6.2994 - val_perplexity_raw: 2.7183\n",
      "Epoch 14/20\n",
      " - 21s - loss: 5.0669 - perplexity_raw: 2.7183 - val_loss: 6.3230 - val_perplexity_raw: 2.7183\n",
      "Epoch 15/20\n",
      " - 23s - loss: 5.0635 - perplexity_raw: 2.7183 - val_loss: 6.3475 - val_perplexity_raw: 2.7183\n",
      "Epoch 16/20\n",
      " - 20s - loss: 5.0646 - perplexity_raw: 2.4038 - val_loss: 6.3760 - val_perplexity_raw: 2.7183\n",
      "Epoch 17/20\n",
      " - 21s - loss: 5.0629 - perplexity_raw: 2.7183 - val_loss: 6.4000 - val_perplexity_raw: 2.7183\n",
      "Epoch 18/20\n",
      " - 20s - loss: 5.0629 - perplexity_raw: 2.7183 - val_loss: 6.4198 - val_perplexity_raw: 2.7183\n",
      "Epoch 19/20\n",
      " - 21s - loss: 5.0587 - perplexity_raw: 2.7183 - val_loss: 6.4366 - val_perplexity_raw: 2.7183\n",
      "Epoch 20/20\n",
      " - 20s - loss: 5.0602 - perplexity_raw: 1.8666 - val_loss: 6.4605 - val_perplexity_raw: 2.7183\n"
     ]
    }
   ],
   "source": [
    "#model = BaseNetwork()\n",
    "model.fit(X_train, X_test, y_train, y_test, arch=\"LSTM_Embedding\", epochs=20, hidden_lstm=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bianca is coming xD nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"Bianca is coming xD\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good morning nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca nbianca'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"Good morning\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
