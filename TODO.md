TODO:
 * Autodescarga de embeddings si no tan
 * Vocab size segun la distribucion del dataset, usar num owrds del tokenizer y borrar ñapa
 * cambiar la base network y poner para elegir lo que hay (diciendo en comentarios que es nefasto de cara a la memoria), globalaveragepooling1d y maxaveragepooling1d
* añadir un buen callback de earlystoping y otro de checkpoint y save best model
